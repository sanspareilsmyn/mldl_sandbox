{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_in_50_lines_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD5Db4yHXw0FVJHae2NhI1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanspareilsmyn/mldl_sandbox/blob/main/GAN_in_50_lines_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tn4cinyXDeob",
        "outputId": "96e7ceeb-d3d9-4b50-a82c-6b88357c3bbf"
      },
      "source": [
        "\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# Generative Adversarial Networks (GAN) example in PyTorch. Tested with PyTorch 0.4.1, Python 3.6.7 (Nov 2018)\n",
        "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "matplotlib_is_available = True\n",
        "try:\n",
        "  from matplotlib import pyplot as plt\n",
        "except ImportError:\n",
        "  print(\"Will skip plotting; matplotlib is not available.\")\n",
        "  matplotlib_is_available = False\n",
        "\n",
        "# Data params\n",
        "data_mean = 4\n",
        "data_stddev = 1.25\n",
        "\n",
        "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
        "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
        "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
        "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
        "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
        "\n",
        "print(\"Using data [%s]\" % (name))\n",
        "\n",
        "# ##### DATA: Target data and generator input data\n",
        "\n",
        "def get_distribution_sampler(mu, sigma):\n",
        "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
        "\n",
        "def get_generator_input_sampler():\n",
        "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
        "\n",
        "# ##### MODELS: Generator model and discriminator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Generator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.map1(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map2(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map3(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.f(self.map1(x))\n",
        "        x = self.f(self.map2(x))\n",
        "        return self.f(self.map3(x))\n",
        "\n",
        "def extract(v):\n",
        "    return v.data.storage().tolist()\n",
        "\n",
        "def stats(d):\n",
        "    return [np.mean(d), np.std(d)]\n",
        "\n",
        "def get_moments(d):\n",
        "    # Return the first 4 moments of the data provided\n",
        "    mean = torch.mean(d)\n",
        "    diffs = d - mean\n",
        "    var = torch.mean(torch.pow(diffs, 2.0))\n",
        "    std = torch.pow(var, 0.5)\n",
        "    zscores = diffs / std\n",
        "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
        "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
        "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
        "    return final\n",
        "\n",
        "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
        "    mean = torch.mean(data.data, 1, keepdim=True)\n",
        "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
        "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
        "    if remove_raw_data:\n",
        "        return torch.cat([diffs], 1)\n",
        "    else:\n",
        "        return torch.cat([data, diffs], 1)\n",
        "\n",
        "def train():\n",
        "    # Model parameters\n",
        "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
        "    g_hidden_size = 5     # Generator complexity\n",
        "    g_output_size = 1     # Size of generated output vector\n",
        "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
        "    d_hidden_size = 10    # Discriminator complexity\n",
        "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
        "    minibatch_size = d_input_size\n",
        "\n",
        "    d_learning_rate = 1e-3\n",
        "    g_learning_rate = 1e-3\n",
        "    sgd_momentum = 0.9\n",
        "\n",
        "    num_epochs = 5000\n",
        "    print_interval = 100\n",
        "    d_steps = 20\n",
        "    g_steps = 20\n",
        "\n",
        "    dfe, dre, ge = 0, 0, 0\n",
        "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
        "\n",
        "    discriminator_activation_function = torch.sigmoid\n",
        "    generator_activation_function = torch.tanh\n",
        "\n",
        "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
        "    gi_sampler = get_generator_input_sampler()\n",
        "    G = Generator(input_size=g_input_size,\n",
        "                  hidden_size=g_hidden_size,\n",
        "                  output_size=g_output_size,\n",
        "                  f=generator_activation_function)\n",
        "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
        "                      hidden_size=d_hidden_size,\n",
        "                      output_size=d_output_size,\n",
        "                      f=discriminator_activation_function)\n",
        "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
        "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for d_index in range(d_steps):\n",
        "            # 1. Train D on real+fake\n",
        "            D.zero_grad()\n",
        "\n",
        "            #  1A: Train D on real\n",
        "            d_real_data = Variable(d_sampler(d_input_size))\n",
        "            d_real_decision = D(preprocess(d_real_data))\n",
        "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1])))  # ones = true\n",
        "            d_real_error.backward() # compute/store gradients, but don't change params\n",
        "\n",
        "            #  1B: Train D on fake\n",
        "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
        "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1])))  # zeros = fake\n",
        "            d_fake_error.backward()\n",
        "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "\n",
        "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
        "\n",
        "        for g_index in range(g_steps):\n",
        "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "            G.zero_grad()\n",
        "\n",
        "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            g_fake_data = G(gen_input)\n",
        "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
        "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1])))  # Train G to pretend it's genuine\n",
        "\n",
        "            g_error.backward()\n",
        "            g_optimizer.step()  # Only optimizes G's parameters\n",
        "            ge = extract(g_error)[0]\n",
        "\n",
        "        if epoch % print_interval == 0:\n",
        "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
        "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
        "\n",
        "    if matplotlib_is_available:\n",
        "        print(\"Plotting the generated distribution...\")\n",
        "        values = extract(g_fake_data)\n",
        "        print(\" Values: %s\" % (str(values)))\n",
        "        plt.hist(values, bins=50)\n",
        "        plt.xlabel('Value')\n",
        "        plt.ylabel('Count')\n",
        "        plt.title('Histogram of Generated Distribution')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "train()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using data [Only 4 moments]\n",
            "Epoch 0: D (0.7304531931877136 real_err, 0.6656383872032166 fake_err) G (0.7210499048233032 err); Real Dist ([4.096029117584228, 1.173346471524314]),  Fake Dist ([0.26481537976861, 0.030505799306925457]) \n",
            "Epoch 100: D (0.6351064443588257 real_err, 0.48079755902290344 fake_err) G (0.9563900232315063 err); Real Dist ([4.00207530426979, 1.2860850289879309]),  Fake Dist ([4.571523983955383, 0.1757854145667001]) \n",
            "Epoch 200: D (0.6130784749984741 real_err, 0.5720502138137817 fake_err) G (0.8254655003547668 err); Real Dist ([4.032171373009682, 1.243878465068883]),  Fake Dist ([3.505586124897003, 2.4808649619942136]) \n",
            "Epoch 300: D (0.20641463994979858 real_err, 0.22224248945713043 fake_err) G (1.5423260927200317 err); Real Dist ([4.028013439953328, 1.2731351295655549]),  Fake Dist ([0.38832351183891295, 1.4608331590737784]) \n",
            "Epoch 400: D (0.7140291333198547 real_err, 0.6980460286140442 fake_err) G (0.6925403475761414 err); Real Dist ([4.08597998726368, 1.2529775157094543]),  Fake Dist ([4.897165663719178, 0.2415505539833282]) \n",
            "Epoch 500: D (0.7743290662765503 real_err, 0.7240809798240662 fake_err) G (0.6583450436592102 err); Real Dist ([3.9415379803180697, 1.3175542824237114]),  Fake Dist ([4.756724159955978, 1.3614538987247762]) \n",
            "Epoch 600: D (0.7004173398017883 real_err, 0.6951281428337097 fake_err) G (0.6918783783912659 err); Real Dist ([4.021096144974232, 1.2716749651710881]),  Fake Dist ([4.347211429357529, 2.080098356494356]) \n",
            "Epoch 700: D (0.6616544723510742 real_err, 0.6629173755645752 fake_err) G (0.7206994891166687 err); Real Dist ([4.018987317040563, 1.2161633103902223]),  Fake Dist ([4.0743139176368715, 1.866350303789875]) \n",
            "Epoch 800: D (0.6945129036903381 real_err, 0.6985527873039246 fake_err) G (0.6874423027038574 err); Real Dist ([4.066475823521614, 1.2495657999307614]),  Fake Dist ([3.9151589660644532, 0.6834993526135033]) \n",
            "Epoch 900: D (0.6912034749984741 real_err, 0.6914534568786621 fake_err) G (0.6958048343658447 err); Real Dist ([3.9688981559500096, 1.2651571988375725]),  Fake Dist ([4.277773919820786, 1.065116408952289]) \n",
            "Epoch 1000: D (0.6898801326751709 real_err, 0.6976390480995178 fake_err) G (0.6927948594093323 err); Real Dist ([3.914049292564392, 1.2683447690060643]),  Fake Dist ([4.01939641559124, 1.2092379838941738]) \n",
            "Epoch 1100: D (0.6913094520568848 real_err, 0.6949129104614258 fake_err) G (0.6916429400444031 err); Real Dist ([3.998700097680092, 1.260183074911288]),  Fake Dist ([3.9652287155389785, 1.3875021880256826]) \n",
            "Epoch 1200: D (0.6926561594009399 real_err, 0.6930140256881714 fake_err) G (0.6925950646400452 err); Real Dist ([4.0166231198310856, 1.2962442350770376]),  Fake Dist ([3.9448608701229095, 1.459353197674347]) \n",
            "Epoch 1300: D (0.6946740746498108 real_err, 0.6924641132354736 fake_err) G (0.6915833950042725 err); Real Dist ([3.970220458030701, 1.1997543882122548]),  Fake Dist ([3.9399049575328826, 1.2843593251200491]) \n",
            "Epoch 1400: D (0.6931109428405762 real_err, 0.6936317682266235 fake_err) G (0.692070484161377 err); Real Dist ([4.016802043110133, 1.306783371890944]),  Fake Dist ([4.021882811188698, 1.1549275410058453]) \n",
            "Epoch 1500: D (0.6930445432662964 real_err, 0.6935575604438782 fake_err) G (0.6927555203437805 err); Real Dist ([3.963286432176828, 1.2418928927763082]),  Fake Dist ([4.092865601778031, 1.114442338987581]) \n",
            "Epoch 1600: D (0.6933404803276062 real_err, 0.6915228366851807 fake_err) G (0.6936596632003784 err); Real Dist ([3.993850094139576, 1.1679757369515085]),  Fake Dist ([4.076229881763458, 1.2363150199249244]) \n",
            "Epoch 1700: D (0.6921378970146179 real_err, 0.6938233375549316 fake_err) G (0.6923654675483704 err); Real Dist ([3.902483914300799, 1.3105513386773915]),  Fake Dist ([4.015870004653931, 1.2665537374274984]) \n",
            "Epoch 1800: D (0.6927252411842346 real_err, 0.6926060914993286 fake_err) G (0.6928102374076843 err); Real Dist ([4.117671575963497, 1.284334512208317]),  Fake Dist ([3.9676677724123, 1.3932355902150588]) \n",
            "Epoch 1900: D (0.6925813555717468 real_err, 0.6935840845108032 fake_err) G (0.6927081346511841 err); Real Dist ([4.053387265086174, 1.19529076953838]),  Fake Dist ([3.9103089923858643, 1.3721903444711865]) \n",
            "Epoch 2000: D (0.6940223574638367 real_err, 0.6935271620750427 fake_err) G (0.6929289102554321 err); Real Dist ([3.9827522418498993, 1.3347223116843718]),  Fake Dist ([4.059667117476463, 1.273413283538675]) \n",
            "Epoch 2100: D (0.6928841471672058 real_err, 0.693655252456665 fake_err) G (0.69263756275177 err); Real Dist ([3.8909035961627962, 1.198992165456993]),  Fake Dist ([4.039828825473785, 1.2325575340350985]) \n",
            "Epoch 2200: D (0.6927283406257629 real_err, 0.6933965682983398 fake_err) G (0.6924560070037842 err); Real Dist ([4.036749982178211, 1.22514272114784]),  Fake Dist ([4.102694740772248, 1.1879400941291043]) \n",
            "Epoch 2300: D (0.6926182508468628 real_err, 0.6937189698219299 fake_err) G (0.6925497651100159 err); Real Dist ([4.02317615275085, 1.2446241131422549]),  Fake Dist ([4.005082518696785, 1.228908500625383]) \n",
            "Epoch 2400: D (0.6932582855224609 real_err, 0.6933003664016724 fake_err) G (0.6929349899291992 err); Real Dist ([3.958986320439726, 1.2603321905479092]),  Fake Dist ([3.9226663504838943, 1.2365534349223943]) \n",
            "Epoch 2500: D (0.6928268074989319 real_err, 0.6936060190200806 fake_err) G (0.6926878690719604 err); Real Dist ([4.0880295840799805, 1.2537429095251296]),  Fake Dist ([4.067030334353447, 1.2292930883308197]) \n",
            "Epoch 2600: D (0.6928338408470154 real_err, 0.6933172941207886 fake_err) G (0.6926779747009277 err); Real Dist ([4.047901075318456, 1.2527338105254953]),  Fake Dist ([4.103323587179184, 1.2068802827336584]) \n",
            "Epoch 2700: D (0.692950963973999 real_err, 0.6936235427856445 fake_err) G (0.692643404006958 err); Real Dist ([4.048146555483341, 1.2310409462236818]),  Fake Dist ([4.009959763765335, 1.2952740732982606]) \n",
            "Epoch 2800: D (0.6929024457931519 real_err, 0.6932443380355835 fake_err) G (0.6930152177810669 err); Real Dist ([3.9953391120433808, 1.2371790486694894]),  Fake Dist ([4.0865732251405715, 1.2278725454498058]) \n",
            "Epoch 2900: D (0.6932640075683594 real_err, 0.6931350231170654 fake_err) G (0.6929885149002075 err); Real Dist ([4.059048784546554, 1.2630071720327658]),  Fake Dist ([3.9167626971006393, 1.2416648797702887]) \n",
            "Epoch 3000: D (0.6929128170013428 real_err, 0.6932169198989868 fake_err) G (0.6932251453399658 err); Real Dist ([4.044596119761467, 1.3020690992794408]),  Fake Dist ([3.9862649220228197, 1.2745487262584596]) \n",
            "Epoch 3100: D (0.6933236718177795 real_err, 0.6930999755859375 fake_err) G (0.6929804086685181 err); Real Dist ([3.9985152142047884, 1.2019321143444397]),  Fake Dist ([3.9602552217245104, 1.2063365591614217]) \n",
            "Epoch 3200: D (0.6938719153404236 real_err, 0.6932196617126465 fake_err) G (0.6931331157684326 err); Real Dist ([4.0344846543371675, 1.1943862202354965]),  Fake Dist ([4.068176504135132, 1.2073965086739673]) \n",
            "Epoch 3300: D (0.6930505037307739 real_err, 0.6933351755142212 fake_err) G (0.693541407585144 err); Real Dist ([4.120278314650059, 1.2864499676465804]),  Fake Dist ([3.9265735785961153, 1.28878809303519]) \n",
            "Epoch 3400: D (0.6930257081985474 real_err, 0.6924965381622314 fake_err) G (0.6930077075958252 err); Real Dist ([4.048327512323857, 1.3053165277510164]),  Fake Dist ([4.0220475635528565, 1.1688318742702224]) \n",
            "Epoch 3500: D (0.692678689956665 real_err, 0.6934899687767029 fake_err) G (0.6929934024810791 err); Real Dist ([4.034616230010986, 1.2503797605567302]),  Fake Dist ([4.033915943622589, 1.2772875022314563]) \n",
            "Epoch 3600: D (0.6944611668586731 real_err, 0.6933075189590454 fake_err) G (0.6929159164428711 err); Real Dist ([3.984346147492528, 1.277073174132172]),  Fake Dist ([3.929435860157013, 1.2126359423682094]) \n",
            "Epoch 3700: D (0.6930946111679077 real_err, 0.6936745643615723 fake_err) G (0.6927220225334167 err); Real Dist ([4.021940387129783, 1.2469161754372333]),  Fake Dist ([3.935784788131714, 1.2476769488647332]) \n",
            "Epoch 3800: D (0.6927997469902039 real_err, 0.6933140754699707 fake_err) G (0.6935839056968689 err); Real Dist ([4.053954262644052, 1.22581114261439]),  Fake Dist ([4.028570748329162, 1.1617962446729404]) \n",
            "Epoch 3900: D (0.6935203671455383 real_err, 0.6931110620498657 fake_err) G (0.6929062604904175 err); Real Dist ([4.058676337480545, 1.2122855631334066]),  Fake Dist ([4.039502663254738, 1.3143206744145721]) \n",
            "Epoch 4000: D (0.6930679082870483 real_err, 0.6933021545410156 fake_err) G (0.6927970051765442 err); Real Dist ([3.977196958363056, 1.2576436158347744]),  Fake Dist ([3.9990071431398393, 1.2949450436106251]) \n",
            "Epoch 4100: D (0.6941653490066528 real_err, 0.6932163238525391 fake_err) G (0.6932634115219116 err); Real Dist ([3.8990032828599213, 1.2176281388710748]),  Fake Dist ([3.9353443810939788, 1.2388625243899605]) \n",
            "Epoch 4200: D (0.6930733919143677 real_err, 0.6932734251022339 fake_err) G (0.6930176019668579 err); Real Dist ([3.982551335632801, 1.2974935006969803]),  Fake Dist ([3.9664452040195464, 1.302108491813319]) \n",
            "Epoch 4300: D (0.6932084560394287 real_err, 0.6933273077011108 fake_err) G (0.6929116249084473 err); Real Dist ([4.0634931842684745, 1.2624072741660286]),  Fake Dist ([3.848022152543068, 1.2468581823966398]) \n",
            "Epoch 4400: D (0.6934285163879395 real_err, 0.6931153535842896 fake_err) G (0.693117618560791 err); Real Dist ([4.013287863045931, 1.2285876372911135]),  Fake Dist ([4.02339117205143, 1.3487961046861203]) \n",
            "Epoch 4500: D (0.6932635307312012 real_err, 0.6933364868164062 fake_err) G (0.6930204629898071 err); Real Dist ([3.956703767955303, 1.2853332115715683]),  Fake Dist ([4.041868003487587, 1.2743691079554176]) \n",
            "Epoch 4600: D (0.693515956401825 real_err, 0.6931978464126587 fake_err) G (0.6931205987930298 err); Real Dist ([3.957547590792179, 1.2268782433661105]),  Fake Dist ([4.003910461902619, 1.2692217828528036]) \n",
            "Epoch 4700: D (0.6934760212898254 real_err, 0.6932361125946045 fake_err) G (0.6932791471481323 err); Real Dist ([3.9991860828697683, 1.2600022837562175]),  Fake Dist ([4.100861279249191, 1.2323058422394242]) \n",
            "Epoch 4800: D (0.6928572058677673 real_err, 0.6933286190032959 fake_err) G (0.6929479837417603 err); Real Dist ([4.10638880315423, 1.286681475007644]),  Fake Dist ([3.9776208360195158, 1.2304196647803325]) \n",
            "Epoch 4900: D (0.6938778758049011 real_err, 0.693449079990387 fake_err) G (0.69285649061203 err); Real Dist ([3.928746519833803, 1.2562109067591631]),  Fake Dist ([3.957808705806732, 1.2342535616605697]) \n",
            "Plotting the generated distribution...\n",
            " Values: [4.0588788986206055, 3.6701509952545166, 6.495765209197998, 1.4697962999343872, 2.8504185676574707, 4.5863518714904785, 4.575089454650879, 2.3927295207977295, 2.721653461456299, 5.785302639007568, 1.0403674840927124, 6.183096408843994, 5.8736443519592285, 5.0220208168029785, 3.696906805038452, 5.564061164855957, 1.7186323404312134, 3.9396145343780518, 3.703371047973633, 3.5332083702087402, 3.7911126613616943, 3.6438894271850586, 6.507505416870117, 5.834590435028076, 4.658459663391113, 3.6559977531433105, 3.269104480743408, 4.930732727050781, 5.5082106590271, 4.290534496307373, 1.0231714248657227, 2.874638795852661, 4.922638893127441, 4.072793483734131, 3.603302001953125, 3.3717217445373535, 3.325309991836548, 3.666055679321289, 3.7577805519104004, 6.0915961265563965, 3.423128604888916, 2.3392112255096436, 3.8524293899536133, 3.601074457168579, 3.5861687660217285, 6.150638103485107, 1.0040645599365234, 5.093700408935547, 3.4439315795898438, 4.280612945556641, 4.723004341125488, 5.874695301055908, 4.786407947540283, 5.007465362548828, 3.5119800567626953, 2.423546314239502, 5.863711833953857, 5.24052619934082, 3.4432363510131836, 3.593709945678711, 3.6518476009368896, 3.662726879119873, 5.381986141204834, 1.253009557723999, 1.829383134841919, 3.817369222640991, 5.163314342498779, 3.558703899383545, 4.4002790451049805, 1.8888061046600342, 4.980438232421875, 3.6787564754486084, 4.049472332000732, 3.643698215484619, 1.9883248805999756, 0.945564866065979, 5.981492042541504, 4.131321430206299, 3.5816900730133057, 6.475952625274658, 3.283025026321411, 3.276409387588501, 6.469881534576416, 5.322029113769531, 3.541311740875244, 3.4476687908172607, 3.3500967025756836, 2.872134208679199, 4.928016185760498, 4.212815284729004, 3.3129215240478516, 3.3596904277801514, 4.098118782043457, 1.851181983947754, 1.174674391746521, 3.7913260459899902, 3.5873541831970215, 3.505002498626709, 3.1190249919891357, 3.460139751434326, 1.8692500591278076, 3.6734626293182373, 3.8286221027374268, 5.733603477478027, 1.4735151529312134, 5.865713596343994, 1.8319519758224487, 6.0441765785217285, 2.5029304027557373, 5.690453052520752, 6.104735374450684, 6.32717752456665, 3.6757888793945312, 6.243578910827637, 6.529360771179199, 4.571557998657227, 5.752683639526367, 3.5736849308013916, 4.542603969573975, 2.4701924324035645, 3.4585647583007812, 2.56862211227417, 3.589165449142456, 3.44110107421875, 4.101208209991455, 3.768756866455078, 5.274747848510742, 1.3509718179702759, 3.7111573219299316, 6.526242733001709, 1.219423532485962, 3.627810478210449, 4.0505571365356445, 5.662208557128906, 6.070194721221924, 5.376558303833008, 4.111279010772705, 5.608132839202881, 3.525939464569092, 5.257033824920654, 1.0325343608856201, 3.9991185665130615, 3.3145599365234375, 3.6416947841644287, 3.908540725708008, 2.7538161277770996, 5.864593505859375, 4.499485015869141, 3.9867732524871826, 4.378831386566162, 1.314729928970337, 5.524433612823486, 3.6669793128967285, 3.2036380767822266, 3.7318077087402344, 4.3096723556518555, 3.6295740604400635, 4.539294242858887, 3.5768332481384277, 4.205785274505615, 3.678284168243408, 4.400643348693848, 6.471253395080566, 4.788043022155762, 3.5058584213256836, 3.7144670486450195, 5.607579231262207, 3.810264825820923, 6.4678120613098145, 5.452298164367676, 3.4197497367858887, 3.163907527923584, 3.7797322273254395, 5.678390979766846, 3.293396472930908, 2.0528132915496826, 5.548369884490967, 3.7087244987487793, 2.8830056190490723, 6.409012794494629, 5.129217147827148, 4.327888488769531, 1.7883200645446777, 4.803812026977539, 2.6189308166503906, 4.018670558929443, 3.134258270263672, 2.7075307369232178, 3.4696204662323, 3.8376758098602295, 3.5108823776245117, 0.9277505874633789, 3.4313597679138184, 3.642956018447876, 3.6336827278137207, 3.555346965789795, 3.3031609058380127, 2.924354314804077, 3.9212822914123535, 3.867053508758545, 5.723214626312256, 3.5665295124053955, 4.419336795806885, 6.115105152130127, 4.725741863250732, 4.164544105529785, 3.1189401149749756, 3.6396961212158203, 4.685014724731445, 4.203963756561279, 4.5493316650390625, 4.078777313232422, 4.694339275360107, 3.7868990898132324, 5.642380714416504, 3.737704277038574, 5.306321144104004, 5.146431922912598, 3.3813862800598145, 3.8094351291656494, 3.534449577331543, 3.194377899169922, 1.9310752153396606, 5.605222225189209, 4.03920841217041, 2.871781587600708, 4.5564374923706055, 2.0510406494140625, 3.7671923637390137, 4.723428726196289, 2.4903323650360107, 0.9670290350914001, 3.152116298675537, 3.1951804161071777, 4.267979621887207, 3.129399061203003, 6.164154052734375, 3.3000521659851074, 3.670381784439087, 3.936307907104492, 3.91506290435791, 3.5805773735046387, 3.6036438941955566, 3.8715267181396484, 2.9536280632019043, 1.6904934644699097, 3.9973959922790527, 4.6819562911987305, 5.7104315757751465, 5.509852886199951, 4.4886884689331055, 4.927389144897461, 2.161407709121704, 4.268392086029053, 3.2719151973724365, 1.5882893800735474, 4.333466053009033, 4.566753387451172, 4.9134840965271, 2.922818183898926, 3.9273648262023926, 3.4748878479003906, 5.349239826202393, 6.304759502410889, 6.089111804962158, 0.9637917280197144, 3.729372978210449, 3.6609716415405273, 3.301201343536377, 3.8978796005249023, 3.613168239593506, 3.795461893081665, 3.5785892009735107, 5.478078842163086, 4.4240875244140625, 4.1828179359436035, 5.461047649383545, 5.166800498962402, 3.866482734680176, 5.91644811630249, 3.8147783279418945, 3.6494836807250977, 4.252935886383057, 3.168304681777954, 4.051784992218018, 3.251368999481201, 3.560981512069702, 3.7137904167175293, 6.113236427307129, 4.377160549163818, 4.831722259521484, 3.4279441833496094, 4.166632652282715, 4.01805305480957, 3.292907238006592, 1.835386037826538, 4.551914215087891, 6.109716415405273, 3.2681546211242676, 4.313215255737305, 3.3086185455322266, 5.60542106628418, 4.812222480773926, 2.0617787837982178, 2.766493320465088, 6.437647342681885, 5.047807693481445, 6.054558753967285, 4.539294719696045, 3.8893914222717285, 4.8380842208862305, 6.021447658538818, 1.3796519041061401, 3.83644437789917, 3.224757432937622, 3.578380584716797, 3.5482730865478516, 3.0582127571105957, 4.135737419128418, 5.646964073181152, 3.5697269439697266, 4.416600704193115, 2.308220386505127, 4.7278947830200195, 4.519593715667725, 0.9970535635948181, 3.188124895095825, 2.3790359497070312, 3.64445161819458, 4.075774669647217, 4.187270164489746, 3.980036735534668, 4.4656782150268555, 4.839199066162109, 4.219255447387695, 5.773280620574951, 4.328000545501709, 6.480618953704834, 2.9410040378570557, 4.066744804382324, 1.1068859100341797, 6.505906105041504, 3.698953151702881, 3.7620253562927246, 4.853034019470215, 3.5369420051574707, 2.829648971557617, 1.0157220363616943, 0.7853472232818604, 3.940411329269409, 5.042925834655762, 2.979461193084717, 4.467541694641113, 5.465028762817383, 4.433897972106934, 6.065119743347168, 3.710322618484497, 6.252411842346191, 3.5110085010528564, 3.11696457862854, 4.411434650421143, 3.484830856323242, 3.679793119430542, 3.992788076400757, 6.467691898345947, 4.297966957092285, 2.8842272758483887, 4.68174934387207, 2.6983556747436523, 3.6899356842041016, 4.024730682373047, 2.1261672973632812, 5.674483299255371, 5.257260322570801, 4.246419906616211, 3.6932594776153564, 3.998058319091797, 4.0011796951293945, 3.4860684871673584, 3.4310801029205322, 4.258978843688965, 6.162343502044678, 4.82835578918457, 4.752991676330566, 6.15833044052124, 4.565227031707764, 2.0226378440856934, 0.8822568655014038, 3.7440881729125977, 3.542678117752075, 3.598910331726074, 2.821714401245117, 6.161514759063721, 3.69528865814209, 1.8286267518997192, 5.383566379547119, 6.13201379776001, 4.436939716339111, 3.7685205936431885, 1.59267258644104, 1.768968105316162, 1.0370008945465088, 3.876465320587158, 3.4721806049346924, 4.17600154876709, 3.5167624950408936, 3.6586203575134277, 4.319415092468262, 5.400007247924805, 3.7460341453552246, 4.3051605224609375, 0.8705265522003174, 3.0158936977386475, 3.7416229248046875, 3.3646442890167236, 3.0207085609436035, 1.5760356187820435, 5.259304046630859, 3.450878143310547, 3.9931092262268066, 3.306511878967285, 3.50870680809021, 5.886877059936523, 3.9099245071411133, 4.145063400268555, 3.8626253604888916, 1.9420793056488037, 1.5245826244354248, 3.660123348236084, 3.8062679767608643, 5.47197151184082, 3.743783950805664, 1.6612522602081299, 2.0227882862091064, 3.9327385425567627, 3.70047664642334, 2.712418794631958, 6.341622829437256, 3.4789013862609863, 3.6206326484680176, 4.0020036697387695, 4.436909198760986, 3.6586432456970215, 1.510658860206604, 4.545930862426758, 3.9897022247314453, 3.7311818599700928, 6.071315765380859, 5.939821243286133, 3.073897361755371, 4.196744441986084, 0.864345908164978, 3.4298439025878906, 6.357191562652588, 4.469478607177734, 3.539419412612915, 6.063974857330322, 6.056122303009033, 3.943903684616089, 6.383896827697754, 4.9210662841796875, 3.8105528354644775, 3.275017738342285, 6.078232765197754, 3.50142240524292, 2.6385271549224854, 3.8963327407836914, 3.5814433097839355, 3.295836925506592, 5.737833023071289, 3.5575437545776367, 4.215367317199707, 3.4691522121429443, 6.425950527191162, 3.6771769523620605, 1.183849573135376, 3.8749172687530518, 3.9406535625457764, 3.6819605827331543, 4.185608386993408, 4.980125427246094, 3.8572516441345215, 4.12125825881958, 4.213788032531738, 2.3276708126068115, 3.7477571964263916, 4.128661155700684, 3.5639607906341553, 5.286649703979492, 2.2143425941467285, 3.4753642082214355, 5.498370170593262, 4.0418291091918945, 4.255025863647461, 4.958976745605469, 4.441300392150879, 3.659660816192627, 4.102571487426758, 4.193197727203369, 3.5272557735443115]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPutiACWDhnL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}