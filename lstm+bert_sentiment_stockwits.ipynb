{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm+bert_sentiment_stockwits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyE3CotKKF46CEl8BH01AX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanspareilsmyn/mldl_sandbox/blob/main/lstm%2Bbert_sentiment_stockwits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2xS7ATk7Snw"
      },
      "source": [
        "'''\n",
        "> ##### Sample input messages ######\n",
        "> print(messages)\n",
        "[\"$AMZN sick! theyâ€™re running a prime flash sale on shares too!\", \n",
        "\"$AAPL has a good Piotroski-F score of 7.00. This indicates a good health and profitability. https://www.chartmill.com/analyze.php?utm_source=stocktwits&amp;utm_medium=FA&amp;utm_content=PROFITABILITY&amp;utm_campaign=social_tracking#/AAPL?r=fa&amp;key=bb853040-a4ac-41c6-b549-d218d2f21b32\", \"$FB got rid of this trash today, \n",
        "i admit that bears were right\", ...]\n",
        "> print(sentiments)\n",
        "[4, 2, 0, ...]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SgiPamu6n8i"
      },
      "source": [
        "# https://towardsdatascience.com/lstm-vs-bert-a-step-by-step-guide-for-tweet-sentiment-analysis-ced697948c47"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhUDJyEn7PeZ"
      },
      "source": [
        "#1. Preprocessing"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTSta6eO7RJe"
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess(message):\n",
        "  '''\n",
        "  This function takes a string as input, then performs these operations:\n",
        "  - lowercase\n",
        "  - remove URLs\n",
        "  - remove ticker symbols\n",
        "  - remove punctuation\n",
        "  - remove any single character tokens\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "    message : The text message to be preprocessed\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "    text : The preprocessed text\n",
        "  '''\n",
        "\n",
        "  # Lowercase the messsage\n",
        "  text = message.lower()\n",
        "  # Replace URLs with a space in the message\n",
        "  text = re.sub('https?:\\/\\/[a-zA-Z0-9@:%._\\/+~#=?&;-]*', ' ', text)\n",
        "  # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
        "  text = re.sub('\\$[a-zA-Z0-9]*', ' ', text)\n",
        "  # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
        "  text = re.sub('\\@[a-zA-Z0-9]*', ' ', text)\n",
        "  # Replace everything not a letter or apostrophe with a space\n",
        "  text = re.sub('[^a-zA-Z\\']', ' ', text)\n",
        "  # Remove single letter words\n",
        "  text = ' '.join( [w for w in text.split() if len(w) > 1] )\n",
        "\n",
        "  return text\n",
        "\n",
        "# Process for all messages\n",
        "preprocessed = [preprocess(message) for message in tqdm(messages)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM947Uja84Ui"
      },
      "source": [
        "'''\n",
        "> ###### Input messages after preprocessing ######\n",
        "> print(preprocessed)\n",
        "[\"sick they re running a prime flash sale on shares too\", \n",
        "\"has a good piotroski f score of this indicates a good health and profitability\", \n",
        "\"got rid of this trash today i admit that bears were right\", ...]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z7Evui68-La"
      },
      "source": [
        "#2. Tokenize"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs1OqkHA9Axk"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def tokenize_text(text, option):\n",
        "  '''\n",
        "  Tokenize the input text as per specified option\n",
        "    1. Use python split() function\n",
        "    2. Use regex to extract alphabets plus 's and 't\n",
        "    3. Use NLTK word_tokenize()\n",
        "    4. Use NLTK word_tokenize(), remove stopwords and apply lemmatization\n",
        "  '''\n",
        "\n",
        "  if option == 1:\n",
        "    return text.split()\n",
        "  elif option == 2:\n",
        "    return re.findall(r'\\b([[a-zA-Z]+n\\'t|[a-zA-Z]+\\'s|[a-zA-Z]+)\\b', text)\n",
        "  elif option == 3:\n",
        "    return [word for word in word_tokenize(text) if (word.isalpha()==1)]\n",
        "  elif option == 4:\n",
        "    words = [word for word in word_tokenize(text) if (word.isalpha()==1)]\n",
        "    # Remove stop words\n",
        "    stop = set(stopwords.words('english'))\n",
        "    words = [word for word in words if (word not in stop)]\n",
        "    # Lemmatize words (first noun, then verb)\n",
        "    wnl = nltk.stem.WordNetLemmatizer()\n",
        "    lemmatized = [wnl.lemmatize(wnl.lemmatize(word, 'n'), 'v') for word in words]\n",
        "    return lemmatized\n",
        "  else:\n",
        "    logger.warn(\"Please specify option value between 1 and 4\")\n",
        "    return []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZGMOn0R9A0I"
      },
      "source": [
        "#3. Corpus and Vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI3FIOpz9A20"
      },
      "source": [
        "def create_vocab(messages, show_graph=False):\n",
        "  corpus = []\n",
        "  for message in tqdm(messages, desc=\"Tokenizing\"):\n",
        "    tokens = tokenize_text(message, 3)\n",
        "    corpus.extend(tokens)\n",
        "  logger.info(\"The number of all words: {}\".format(len(corpus)))\n",
        "\n",
        "  # Create Counter\n",
        "  counts = Counter(corpus)\n",
        "  logger.info(\"Top 40 frequent words: {}\".format(bow[:40]))\n",
        "\n",
        "  # Indexing vocab, starting from 1\n",
        "  vocab = {word : ii for ii, word in enumerate(counts, 1)}\n",
        "  id2vocab = {v: k for k, v, in vocab.items()}\n",
        "\n",
        "  if show_graph:\n",
        "      from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "      # Generate Word Cloud image\n",
        "      text = \" \".join(corpus)\n",
        "      stopwords = set(STOPWORDS)\n",
        "      stopwords.update([\"will\", \"report\", \"reporting\", \"market\", \"stock\", \"share\"])\n",
        "\n",
        "      wordcloud = WordCloud(stopwords=stopwords, max_font_size=50, max_words=100, background_color=\"white\", collocations=False).generate(text)\n",
        "      plt.figure(figsize=(15,7))\n",
        "      plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "      plt.axis(\"off\")\n",
        "      plt.show()\n",
        "\n",
        "      # Show most frequent words in a bar graph\n",
        "      most = counts.most_common()[:80]\n",
        "      x, y = [], []\n",
        "      for word, count in most:\n",
        "          if word not in stopwords:\n",
        "              x.append(word)\n",
        "              y.append(count)\n",
        "      plt.figure(figsize=(12,10))\n",
        "      sns.barplot(x=y, y=x)\n",
        "      plt.show()\n",
        "\n",
        "  return vocab\n",
        "\n",
        "vocab= create_vocab(preprocessed, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGab0CR9A5u"
      },
      "source": [
        "#4. LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KW0Y3N89A8X"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class LstmTextClassifier(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, lstm_size, dense_size, output_size, lstm_layers=2, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_size = embed_size\n",
        "    self.lstm_size = lstm_size\n",
        "    self.dense_size = dense_size\n",
        "    self.output_size = output_size\n",
        "    self.lstm_layers = lstm_layers\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size, lstm_size, lstm_layers, dropout=dropout, batch_first=False)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    # Insert an additionall fully connected when combining with other inputs\n",
        "    if dense_size == 0:\n",
        "      self.fc = nn.Linear(lstm_size, output_size)\n",
        "    else:\n",
        "      self.fc1 = nn.Linear(lstm_size, dense_size)\n",
        "      self.fc2 = nn.Linear(dense_size, output_size)\n",
        "\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    '''\n",
        "    Initialize the hidden state\n",
        "    '''\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_(),\n",
        "              weight.new(self.lstm_layers, batch_size, self.lstm_size).zero_())\n",
        "    \n",
        "    return hidden\n",
        "\n",
        "  def forward(self, nn_input_text, hidden_state):\n",
        "    '''\n",
        "    Perform a forward pass of the model on nn_input\n",
        "    '''\n",
        "    batch_size = nn_input_text.size(0)\n",
        "    nn_input_text = nn_input_text.long()\n",
        "    embeds = self.embedding(nn_input_text)\n",
        "    lstm_out, hidden_state = self.lstm(embeds, hidden_state)\n",
        "    # Stack up LSTM outputs, apply dropout\n",
        "    lstm_out = lstm_out[-1, :, :]\n",
        "    lstm_out = self.dropout(lstm_out)\n",
        "    # Insert an additional fully connected when combining with other inputs\n",
        "    if self.dense_size == 0:\n",
        "      out = self.fc(lstm_out)\n",
        "    else:\n",
        "      dense_out = self.fc1(lstm_out)\n",
        "      out = self.fc2(dense_out)\n",
        "\n",
        "    logps = self.softmax(out)\n",
        "\n",
        "    return logps, hidden_state\n",
        "\n",
        "# Define LSTM Tokenizer\n",
        "def tokenizer_lstm(X, vocab, seq_len, padding):\n",
        "  '''\n",
        "  Returns tokenized tensor with left/right padding at the specified sequence length\n",
        "  '''\n",
        "  X_tmp = np.zeros((len(X), seq_len), dtype=np.int64)\n",
        "  for i, text in enumerate(X):\n",
        "    tokens = tokenize_text(text, 3)\n",
        "    token_ids = [vocab[word] for word in tokens] \n",
        "    end_idx = min(len(token_ids), seq_len)\n",
        "    if padding == 'right':\n",
        "      X_tmp[i,:end_idx] = token_ids[:end_idx]\n",
        "    elif padding == 'left':\n",
        "      start_idx = max(seq_len - len(token_ids), 0)\n",
        "      X_tmp[i,start_idx:] = token_ids[:end_idx]\n",
        "\n",
        "  return torch.tensor(X_tmp, dtype=torch.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGvP9zxT9A_r"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK35gP2GGfFN"
      },
      "source": [
        "#6. Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GBStkFKGfIE"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define a DataSet Class which simply return (x, y) pair\n",
        "class SimpleDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.datalist = [(x[i], y[i]) for i in range(len(y))]\n",
        "  def __len__(self):\n",
        "    return len(self.datalist)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.datalist[idx]\n",
        "\n",
        "# Data Loader\n",
        "def create_data_loader(X, y, indices, batch_size, shuffle):\n",
        "  X_sampled = np.array(X, dtype=object)[indices]\n",
        "  y_sampled = np.array(y)[indices].astype(int)\n",
        "  dataset = SimpleDataset(X_sampled, y_sampled)\n",
        "  loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "  return loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9awyc7pGfLc"
      },
      "source": [
        "#7. Sampling Cycle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ4zVLoUGfOc"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def train_cycles(X_all, y_all, vocab, num_samples, model_type, epochs, patience, batch_size, seq_len, lr, clip, log_level):\n",
        "  result = pd.DataFrame(colums=['Accuracy', 'F1(macro)', 'Total_Time', 'ms/text'], index=num_samples)\n",
        "\n",
        "  for n in num_samples:\n",
        "    print(\"\")\n",
        "    logger.info(\"############### Start training for %d samples ###############\" %n)\n",
        "\n",
        "    # Stratified sampling\n",
        "    train_size = n / len(y_all)\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size, test_size=train_size*0.2, random_state=rand_seed)\n",
        "    train_indices, valid_indices = next(sss.split(X_all, y_all))\n",
        "\n",
        "    # Sample input data\n",
        "    train_loader = create_data_loader(X_all, y_all, train_indices, batch_size, True)\n",
        "    valid_loader = create_data_loader(X_all, y_all, valid_indices, batch_size, False)\n",
        "\n",
        "    if model_type == 'LSTM':\n",
        "      model = LstmTextClassifier(len(vocab)+1, embed_size=512, lstm_size=1024, dense_size=0, output_size=5, lstm_layers=4, dropout=0.2)\n",
        "      model.embedding.weight.data.uniform_(-1, 1)\n",
        "    elif model_type == 'BERT':\n",
        "      model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
        "\n",
        "    start_time = time.perf_counter()\n",
        "    acc, f1, model_trained = train_nn_model(model, model_type, train_loader, valid_loader, vocab, epochs, patience, batch_size, seq_len, lr, clip, log_level)\n",
        "    end_time = time.perf_counter()\n",
        "    duration = end_time - start_time\n",
        "    logger.info(\"Process Time (sec): {}\".format(duration))\n",
        "    result.loc[n] = (round(acc,4), round(f1,4), duration, duration/n*1000)\n",
        "\n",
        "  return result, model_trained\n",
        "\n",
        "# Define metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def metric(y_true, y_pred):\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred, average='macro')\n",
        "  return acc, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_IkZC3yGfR4"
      },
      "source": [
        "#8. Training the Neural Net Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFo0d89JRyL"
      },
      "source": [
        "from transformers import AdamW as AdamW_HF, get_linear_schedule_with_warmup\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQdcD7ykJR05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIuHtfRbJR55"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWM4Nt_CJR8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgUIlH6nJSC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvg_sWXzJSFi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeKM8QrXJSAc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}