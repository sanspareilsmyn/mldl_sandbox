{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOynGCVOVlc+dFe3PWGbSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanspareilsmyn/mldl_sandbox/blob/main/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKbspRxwShFh"
      },
      "source": [
        "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07zAhT9uSUa4"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE3mrPfUSiIX"
      },
      "source": [
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:80]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[80:]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyI-OfGESno-"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "# and then we send them to the chosen device\n",
        "\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJJj7BBTQgl",
        "outputId": "4cf8ff31-c3e1-4a45-d101-2c0761b6ba92"
      },
      "source": [
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCVRc9TPTbwn",
        "outputId": "9b16ae39-9e93-43c2-eba1-df85a0e37663"
      },
      "source": [
        "# FIRST\n",
        "# Initializes parameters \"a\" and \"b\" randomly, ALMOST as we did in Numpy\n",
        "# since we want to apply gradient descent on these parameters, we need\n",
        "# to set REQUIRES_GRAD = TRUE\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "print(a, b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.1742], requires_grad=True) tensor([-0.1160], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sED9UCDOTx6_",
        "outputId": "ca763ddf-6b89-4a0a-be9c-fed2cd3cef9c"
      },
      "source": [
        "# SECOND\n",
        "# But what if we want to run it on a GPU? We could just send them to device, right?\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "print(a, b)\n",
        "# Sorry, but NO! The to(device) \"shadows\" the gradient..."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.1646], requires_grad=True) tensor([0.1607], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0MRRS7WUIbx",
        "outputId": "0d57b280-6f8d-4c9f-fadb-1e2b0d91368d"
      },
      "source": [
        "# THIRD\n",
        "# We can either create regular tensors and send them to the device (as we did with our data)\n",
        "a = torch.randn(1, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, dtype=torch.float).to(device)\n",
        "# and THEN set them as requiring gradients...\n",
        "a.requires_grad_()\n",
        "b.requires_grad_()\n",
        "print(a, b)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.1920], requires_grad=True) tensor([0.1483], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bObMY1MpULuE",
        "outputId": "513ead38-0a30-47ce-cd25-d30649f28817"
      },
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  yhat = a + b * x_train_tensor\n",
        "  error = y_train_tensor - yhat\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  loss.backward()\n",
        "  \n",
        "  # Let's check the computed gradients...\n",
        "  #print(a.grad)\n",
        "  #print(b.grad)\n",
        "\n",
        "  # What about UPDATING the parameters? Not so fast...\n",
        "\n",
        "  # FIRST ATTEMPT\n",
        "  # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "  # a = a - lr * a.grad\n",
        "  # b = b - lr * b.grad\n",
        "  # print(a)\n",
        "\n",
        "  # SECOND ATTEMPT\n",
        "  # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "  # a -= lr * a.grad\n",
        "  # b -= lr * b.grad        \n",
        "\n",
        "  # THIRD ATTEMPT\n",
        "  # We need to use NO_GRAD to keep the update out of the gradient computation\n",
        "  # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "  with torch.no_grad():\n",
        "      a -= lr * a.grad\n",
        "      b -= lr * b.grad\n",
        "\n",
        "  # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "  a.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWkKWw3cVPXF",
        "outputId": "ba669569-21d3-444a-b4da-39f9e10e339f"
      },
      "source": [
        "# Optimizer\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  yhat = a + b * x_train_tensor\n",
        "  error = y_train_tensor - yhat\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ce4yMxCaoxx",
        "outputId": "543249a5-af46-4980-fb37-42f590aa14be"
      },
      "source": [
        "# Loss\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  yhat = a + b * x_train_tensor\n",
        "\n",
        "  loss = loss_fn(y_train_tensor, yhat)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPSmONyxbeHA"
      },
      "source": [
        "# Model\n",
        "class ManualLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.a + self.b * x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFs7fsmyc4N4",
        "outputId": "ae68285a-16b6-43b8-8f75-8dcca85ef26b"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = ManualLinearRegression().to(device)\n",
        "print(model.state_dict())\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # In PyTorch, train() method doesn't perform a training step!\n",
        "  model.train()\n",
        "\n",
        "  yhat = model(x_train_tensor)\n",
        "\n",
        "  loss = loss_fn(y_train_tensor, yhat)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288]))])\n",
            "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKHhwL64dCG1"
      },
      "source": [
        "class LayerLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00v4tWwelmg"
      },
      "source": [
        "# Let's make it generic.\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "  def train_step(x, y):\n",
        "    model.train()\n",
        "    yhat = model(x)\n",
        "    loss = loss_fn(y, yhat)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return loss.item()\n",
        "  # Returns the function that will be called inside the train loop\n",
        "  return train_step"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWglsnU_hJfK",
        "outputId": "1f200897-59ad-44a9-d9df-7f250252dc5e"
      },
      "source": [
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  loss = train_step(x_train_tensor, y_train_tensor)\n",
        "  losses.append(loss)\n",
        "print(model.state_dict())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VokYZv8EhixE",
        "outputId": "a09d1ce0-2e69-43e0-bcff-dbc854793f13"
      },
      "source": [
        "# Dataset\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, x_tensor, y_tensor):\n",
        "    self.x = x_tensor\n",
        "    self.y = y_tensor\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.x[index], self.y[index])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n",
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHh3Q_rAiW3A",
        "outputId": "6bcc1942-4680-4573-af94-d26ec432a84d"
      },
      "source": [
        "# DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "\n",
        "losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # By using dataloader, we're now sending only one mini-batch to the device!\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "    losses.append(loss)\n",
        "\n",
        "print(model.state_dict())\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0291])), ('b', tensor([1.9716]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7kbdIBTip_X"
      },
      "source": [
        "# Random Split\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq0npKZljkIX",
        "outputId": "a3233da2-a995-4311-a367-2cb4ea7e4b11"
      },
      "source": [
        "losses = []\n",
        "val_losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    loss = train_step(x_batch, y_batch)\n",
        "    losses.append(loss)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "      x_val = x_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "\n",
        "      model.eval()\n",
        "      yhat = model(x_val)\n",
        "      val_loss = loss_fn(y_val, yhat)\n",
        "      val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9531]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt0djzK6kYVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmBp5akikYah"
      },
      "source": [
        ""
      ]
    }
  ]
}