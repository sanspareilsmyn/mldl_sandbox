{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_glove_fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLt+KRvwFAiNIs2UE6NsEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanspareilsmyn/mldl_sandbox/blob/main/word2vec_glove_fasttext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKMxHgGCbNrr"
      },
      "source": [
        "# https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQc5U86qbcbT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.max_colwidth = 200\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "NfnCkte6b_ac",
        "outputId": "29a7e183-f0d3-43e8-8abd-1aa7e8ee41ec"
      },
      "source": [
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!']\n",
        "\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus,\n",
        "                          'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px90jT1kcgcb"
      },
      "source": [
        "# Text Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahXFue_rch_p",
        "outputId": "719f1e59-e876-4cfd-c3b2-e9985bfcfb05"
      },
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xX3TQ6kcyGb",
        "outputId": "ff72f619-25df-4f58-dc23-fca7e0421331"
      },
      "source": [
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah1uc290dDYd",
        "outputId": "f1941c56-1ec1-483a-f587-fe883b6d61ce"
      },
      "source": [
        "from nltk.corpus import gutenberg\n",
        "nltk.download('gutenberg')\n",
        "from string import punctuation\n",
        "nltk.download('punkt')\n",
        "\n",
        "bible = gutenberg.sents('bible-kjv.txt') \n",
        "remove_terms = punctuation + '0123456789'\n",
        "\n",
        "norm_bible = [[word.lower() for word in sent if word not in remove_terms] for sent in bible]\n",
        "norm_bible = [' '.join(tok_sent) for tok_sent in norm_bible]\n",
        "norm_bible = filter(None, normalize_corpus(norm_bible))\n",
        "norm_bible = [tok_sent for tok_sent in norm_bible if len(tok_sent.split()) > 2]\n",
        "\n",
        "print('Total lines:', len(bible))\n",
        "print('\\nSample line:', bible[10])\n",
        "print('\\nProcessed line:', norm_bible[10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Total lines: 30103\n",
            "\n",
            "Sample line: ['1', ':', '6', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'a', 'firmament', 'in', 'the', 'midst', 'of', 'the', 'waters', ',', 'and', 'let', 'it', 'divide', 'the', 'waters', 'from', 'the', 'waters', '.']\n",
            "\n",
            "Processed line: god said let firmament midst waters let divide waters waters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSSeEJ7DddgM"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua4Z_NbtdqHg"
      },
      "source": [
        "There are two different model architectures which can be leveraged by Word2Vec to create these word embedding representations. These include,  \n",
        "\n",
        "- The Continuous Bag of Words (CBOW) Model  \n",
        "\n",
        "- The Skip-gram Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLO-uLoRdzjC"
      },
      "source": [
        "## Implementation of Continuous Bag of Words (CBOW) Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrWB0IIxe2uO"
      },
      "source": [
        "1) Using Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8WlI7hle7nd",
        "outputId": "3dc278ba-fa59-4215-d5c5-4bef7660de23"
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "word2id = tokenizer.word_index\n",
        "\n",
        "\n",
        "# Build vocabulary of unique words\n",
        "word2id['PAD'] = 0\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "sentences_bible = [text.text_to_word_sequence(doc) for doc in norm_bible]\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "model_bible = Word2Vec(sentences=sentences_bible, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "'''\n",
        "sentences: the list of split sentences.\n",
        "size: the dimensionality of the embedding vector\n",
        "window: the number of context words you are looking at\n",
        "min_count: tells the model to ignore words with total count less than this number.\n",
        "workers: the number of threads being used\n",
        "sg: whether to use skip-gram or CBOW\n",
        "'''\n",
        "model_bible.wv.most_similar(\"man\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('neighbour', 0.7788341045379639),\n",
              " ('woman', 0.7612396478652954),\n",
              " ('thing', 0.7585771083831787),\n",
              " ('another', 0.739398181438446),\n",
              " ('wise', 0.7227195501327515),\n",
              " ('doeth', 0.7132614850997925),\n",
              " ('imagination', 0.6974213123321533),\n",
              " ('reconciled', 0.6939409971237183),\n",
              " ('brother', 0.6911318898200989),\n",
              " ('utterance', 0.6890194416046143)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CPZvKfVg53L"
      },
      "source": [
        "2) Implementing from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e81QphAihjNk"
      },
      "source": [
        "# Build the corpus vocabulary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf92P4nsfZPn",
        "outputId": "e4f0fc7c-89f0-409f-f85c-fc135f23bc48"
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "word2id = tokenizer.word_index\n",
        "\n",
        "# build vocabulary of unique words\n",
        "word2id['PAD'] = 0\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
        "\n",
        "vocab_size = len(word2id)\n",
        "embed_size = 100\n",
        "window_size = 2\n",
        "\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 12425\n",
            "Vocabulary Sample: [('shall', 1), ('unto', 2), ('lord', 3), ('thou', 4), ('thy', 5), ('god', 6), ('ye', 7), ('said', 8), ('thee', 9), ('upon', 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ-B5p6MhZ30"
      },
      "source": [
        "# Build a CBOW generator"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDNd0s2phnEg",
        "outputId": "84fb1dce-070d-4204-a4bf-ad85e635f28d"
      },
      "source": [
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "  context_length = window_size * 2\n",
        "  for words in corpus:\n",
        "    sentence_length = len(words)\n",
        "    for index, word in enumerate(words):\n",
        "      context_words = []\n",
        "      label_word = []\n",
        "      start = index - window_size\n",
        "      end = index + window_size + 1\n",
        "\n",
        "      context_words.append([words[i] for i in range(start, end) if 0<= i < sentence_length and i != index])\n",
        "      label_word.append(word)\n",
        "\n",
        "      x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
        "      y = np_utils.to_categorical(label_word, vocab_size)\n",
        "      yield (x, y)\n",
        "\n",
        "# Test this out for some samples\n",
        "i = 0\n",
        "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "  if 0 not in x[0]:\n",
        "    print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
        "\n",
        "    if i == 10:\n",
        "        break\n",
        "    i += 1\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context (X): ['old', 'testament', 'james', 'bible'] -> Target (Y): king\n",
            "Context (X): ['first', 'book', 'called', 'genesis'] -> Target (Y): moses\n",
            "Context (X): ['beginning', 'god', 'heaven', 'earth'] -> Target (Y): created\n",
            "Context (X): ['earth', 'without', 'void', 'darkness'] -> Target (Y): form\n",
            "Context (X): ['without', 'form', 'darkness', 'upon'] -> Target (Y): void\n",
            "Context (X): ['form', 'void', 'upon', 'face'] -> Target (Y): darkness\n",
            "Context (X): ['void', 'darkness', 'face', 'deep'] -> Target (Y): upon\n",
            "Context (X): ['spirit', 'god', 'upon', 'face'] -> Target (Y): moved\n",
            "Context (X): ['god', 'moved', 'face', 'waters'] -> Target (Y): upon\n",
            "Context (X): ['god', 'said', 'light', 'light'] -> Target (Y): let\n",
            "Context (X): ['god', 'saw', 'good', 'god'] -> Target (Y): light\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxhOgGHfkXBG"
      },
      "source": [
        "# Build the CBOW model architecture"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Cco0FT1ok6lq",
        "outputId": "1b711471-6cae-4ee4-d0f4-6ad05fd2c341"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "\n",
        "# Build CBOW architecture\n",
        "cbow = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2),\n",
        "    Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)),\n",
        "    Dense(vocab_size, activation='softmax'),\n",
        "])\n",
        "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "# view model summary\n",
        "print(cbow.summary())\n",
        "\n",
        "# visualize model structure\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4, 100)            1242500   \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12425)             1254925   \n",
            "=================================================================\n",
            "Total params: 2,497,425\n",
            "Trainable params: 2,497,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"405pt\" viewBox=\"0.00 0.00 227.00 304.00\" width=\"303pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 223,-300 223,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140372922731544 -->\n<g class=\"node\" id=\"node1\">\n<title>140372922731544</title>\n<polygon fill=\"none\" points=\"12.5,-249.5 12.5,-295.5 206.5,-295.5 206.5,-249.5 12.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-268.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"92.5,-249.5 92.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"92.5,-272.5 150.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"150.5,-249.5 150.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-280.3\">[(?, 4)]</text>\n<polyline fill=\"none\" points=\"150.5,-272.5 206.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-257.3\">[(?, 4)]</text>\n</g>\n<!-- 140372922732440 -->\n<g class=\"node\" id=\"node2\">\n<title>140372922732440</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 219,-212.5 219,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-185.8\">Embedding</text>\n<polyline fill=\"none\" points=\"84,-166.5 84,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"84,-189.5 142,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"142,-166.5 142,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-197.3\">(?, 4)</text>\n<polyline fill=\"none\" points=\"142,-189.5 219,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-174.3\">(?, 4, 100)</text>\n</g>\n<!-- 140372922731544&#45;&gt;140372922732440 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140372922731544-&gt;140372922732440</title>\n<path d=\"M109.5,-249.3799C109.5,-241.1745 109.5,-231.7679 109.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-222.784 109.5,-212.784 106.0001,-222.784 113.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140372922730704 -->\n<g class=\"node\" id=\"node3\">\n<title>140372922730704</title>\n<polygon fill=\"none\" points=\"10,-83.5 10,-129.5 209,-129.5 209,-83.5 10,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-102.8\">Lambda</text>\n<polyline fill=\"none\" points=\"74,-83.5 74,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"74,-106.5 132,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"132,-83.5 132,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-114.3\">(?, 4, 100)</text>\n<polyline fill=\"none\" points=\"132,-106.5 209,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-91.3\">(?, 100)</text>\n</g>\n<!-- 140372922732440&#45;&gt;140372922730704 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140372922732440-&gt;140372922730704</title>\n<path d=\"M109.5,-166.3799C109.5,-158.1745 109.5,-148.7679 109.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-139.784 109.5,-129.784 106.0001,-139.784 113.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140372923664760 -->\n<g class=\"node\" id=\"node4\">\n<title>140372923664760</title>\n<polygon fill=\"none\" points=\"16,-.5 16,-46.5 203,-46.5 203,-.5 16,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"68,-.5 68,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"68,-23.5 126,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"126,-.5 126,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-31.3\">(?, 100)</text>\n<polyline fill=\"none\" points=\"126,-23.5 203,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-8.3\">(?, 12425)</text>\n</g>\n<!-- 140372922730704&#45;&gt;140372923664760 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140372922730704-&gt;140372923664760</title>\n<path d=\"M109.5,-83.3799C109.5,-75.1745 109.5,-65.7679 109.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-56.784 109.5,-46.784 106.0001,-56.784 113.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nt4eqPrlmO-"
      },
      "source": [
        "# Train the model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S8jTUsfmXMY"
      },
      "source": [
        "for epoch in range(1, 6):\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "        i += 1\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        if i % 100000 == 0:\n",
        "            print('Processed {} (context, word) pairs'.format(i))\n",
        "\n",
        "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e490m7A4mjRA"
      },
      "source": [
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKttvPz4oNU-"
      },
      "source": [
        "# Applying Word2Vec features for ML Tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "_9407UJxmkcZ",
        "outputId": "a795eb8f-b7d7-40ae-d887-0818ce03a7a6"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "# Build word2vec model\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in norm_corpus]\n",
        "\n",
        "# Set values for various parameters\n",
        "feature_size = 10\n",
        "window_context = 10\n",
        "min_word_count = 1\n",
        "sample = 1e-3\n",
        "\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size,\n",
        "                              window=window_context, min_count=min_word_count,\n",
        "                              sample=sample, iter=50)\n",
        "\n",
        "# visualize embeddings\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "words = w2v_model.wv.index2word\n",
        "wvs = w2v_model.wv[words]\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0, n_iter=5000, perplexity=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(wvs)\n",
        "labels = words\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbQg0Kt-ppXl"
      },
      "source": [
        "Now suppose we wanted to cluster the eight documents from our toy corpus, we would need to get the document level embeddings from each of the words present in each document. One strategy would be to average out the word embeddings for each word in a document. This is an extremely useful strategy and you can adopt the same for your own problems. Lets apply this now on our corpus to get features for each document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "BFRFUrNIpdAK",
        "outputId": "36e2488a-de51-47b1-9e65-5e277c409f8d"
      },
      "source": [
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "  feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "  nwords = 0.\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocabulary:\n",
        "      nwords = nwords + 1.\n",
        "      feature_vector = np.add(feature_vector, model[word])\n",
        "  if nwords:\n",
        "    feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "  return feature_vector\n",
        "\n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "  vocabulary = set(model.wv.index2word)\n",
        "  features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features) for tokenized_sentence in corpus]\n",
        "  return np.array(features)\n",
        "\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\n",
        "                                             num_features=feature_size)\n",
        "pd.DataFrame(w2v_feature_array)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.003008</td>\n",
              "      <td>0.004487</td>\n",
              "      <td>0.015026</td>\n",
              "      <td>0.010689</td>\n",
              "      <td>0.022471</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.002006</td>\n",
              "      <td>0.011824</td>\n",
              "      <td>-0.017191</td>\n",
              "      <td>-0.012766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.002012</td>\n",
              "      <td>0.013109</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>0.003361</td>\n",
              "      <td>0.008717</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.015118</td>\n",
              "      <td>-0.003328</td>\n",
              "      <td>0.002603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001495</td>\n",
              "      <td>-0.008045</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.012451</td>\n",
              "      <td>0.004382</td>\n",
              "      <td>0.008722</td>\n",
              "      <td>0.023902</td>\n",
              "      <td>0.002959</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>-0.010045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.003531</td>\n",
              "      <td>-0.006812</td>\n",
              "      <td>-0.017983</td>\n",
              "      <td>-0.000916</td>\n",
              "      <td>-0.013305</td>\n",
              "      <td>0.006501</td>\n",
              "      <td>-0.000879</td>\n",
              "      <td>0.011481</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>-0.008094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011616</td>\n",
              "      <td>0.014034</td>\n",
              "      <td>-0.025837</td>\n",
              "      <td>-0.015639</td>\n",
              "      <td>-0.009593</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>-0.010424</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.005666</td>\n",
              "      <td>0.006659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.004205</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.002746</td>\n",
              "      <td>0.008610</td>\n",
              "      <td>0.005399</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>0.027177</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.005112</td>\n",
              "      <td>-0.004721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.013515</td>\n",
              "      <td>-0.000591</td>\n",
              "      <td>0.008565</td>\n",
              "      <td>0.009218</td>\n",
              "      <td>0.019591</td>\n",
              "      <td>0.007003</td>\n",
              "      <td>-0.003347</td>\n",
              "      <td>0.010206</td>\n",
              "      <td>-0.017799</td>\n",
              "      <td>-0.005808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.002643</td>\n",
              "      <td>-0.005892</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>0.011176</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.014879</td>\n",
              "      <td>0.025915</td>\n",
              "      <td>-0.003026</td>\n",
              "      <td>0.014274</td>\n",
              "      <td>-0.004494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         7         8         9\n",
              "0 -0.003008  0.004487  0.015026  ...  0.011824 -0.017191 -0.012766\n",
              "1 -0.002012  0.013109  0.001166  ...  0.015118 -0.003328  0.002603\n",
              "2  0.001495 -0.008045  0.001565  ...  0.002959  0.006698 -0.010045\n",
              "3 -0.003531 -0.006812 -0.017983  ...  0.011481 -0.004647 -0.008094\n",
              "4  0.011616  0.014034 -0.025837  ...  0.007299  0.005666  0.006659\n",
              "5 -0.004205  0.000798  0.002746  ...  0.000617  0.005112 -0.004721\n",
              "6  0.013515 -0.000591  0.008565  ...  0.010206 -0.017799 -0.005808\n",
              "7 -0.002643 -0.005892 -0.004091  ... -0.003026  0.014274 -0.004494\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "eZgpAvYDphNc",
        "outputId": "b1247d86-563e-48d4-e618-262eead1c0cb"
      },
      "source": [
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "ap = AffinityPropagation()\n",
        "ap.fit(w2v_feature_array)\n",
        "cluster_labels = ap.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "      <th>ClusterLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document  ... ClusterLabel\n",
              "0                                      The sky is blue and beautiful.  ...            2\n",
              "1                                   Love this blue and beautiful sky!  ...            2\n",
              "2                        The quick brown fox jumps over the lazy dog.  ...            1\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans  ...            0\n",
              "4                         I love green eggs, ham, sausages and bacon!  ...            0\n",
              "5                    The brown fox is quick and the blue dog is lazy!  ...            1\n",
              "6            The sky is very blue and the sky is very beautiful today  ...            2\n",
              "7                         The dog is lazy but the brown fox is quick!  ...            1\n",
              "\n",
              "[8 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "BD2HUrv5qO0Z",
        "outputId": "6a6281f6-2411-452f-dd75-c3c1e68f28dd"
      },
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "pcs = pca.fit_transform(w2v_feature_array)\n",
        "labels = ap.labels_\n",
        "categories = list(corpus_df['Category'])\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    color = 'orange' if label == 0 else 'blue' if label == 1 else 'green'\n",
        "    annotation_label = categories[i]\n",
        "    x, y = pcs[i]\n",
        "    plt.scatter(x, y, c=color, edgecolors='k')\n",
        "    plt.annotate(annotation_label, xy=(x+1e-4, y+1e-3), xytext=(0, 0), textcoords='offset points')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2GcAPhNrRcR"
      },
      "source": [
        "# Applying FastText features for Machine Learning Tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "DDTznUzBqTg_",
        "outputId": "ac9dd9a6-3aa7-4fe5-9845-ed4b6f421a2f"
      },
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in norm_bible]\n",
        "\n",
        "# Set values for various parameters\n",
        "feature_size = 100    # Word vector dimensionality  \n",
        "window_context = 50          # Context window size                                                                                    \n",
        "min_word_count = 5   # Minimum word count                        \n",
        "sample = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
        "ft_model = FastText(tokenized_corpus, size=feature_size, window=window_context, \n",
        "                    min_count=min_word_count,sample=sample, sg=1, iter=50)\n",
        "                    \n",
        "                    \n",
        "# view similar words based on gensim's FastText model\n",
        "similar_words = {search_term: [item[0] for item in ft_model.wv.most_similar([search_term], topn=5)]\n",
        "                  for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses','famine']}\n",
        "similar_words  "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-582eef0b9e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# sg decides whether to use the skip-gram model (1) or CBOW (0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m ft_model = FastText(tokenized_corpus, size=feature_size, window=window_context, \n\u001b[0;32m---> 14\u001b[0;31m                     min_count=min_word_count,sample=sample, sg=1, iter=50)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, sg, hs, size, alpha, window, min_count, max_vocab_size, word_ngrams, sample, seed, workers, min_alpha, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, min_n, max_n, sorted_vocab, bucket, trim_rule, batch_words, callbacks)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             seed=seed, hs=hs, negative=negative, cbow_mean=cbow_mean, min_alpha=min_alpha, fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_word_vecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlN1mP1ArVRi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}